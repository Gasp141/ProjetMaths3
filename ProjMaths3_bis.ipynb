{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projet Maths 3"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Questions théoriques"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> **1. Quel théorème du cours nous autorise-t-il à estimer l’espérance conditionnelle par la moyenne empirique de simulations conditionnelles.**\n",
    "\n",
    "Rappelons le théorême de la limite centrale : \n",
    "\n",
    "Si les $Z_n$ sont des variables aléatoires réelles, indépendantes et de même loi, de carré intégrable, d'espérance $m$ et de variance $\\sigma^2 >0$, alors les variables $\\frac{S_n -nm}{\\sigma \\sqrt{n}}$ convergent en loi vers une variable aléatoire de loi $\\mathcal{N}(0,1)$.\n",
    "\n",
    "En d'autres termes, $\\sqrt{n}(M_n - m)$ converge vers une variable normale de loi $\\mathcal{N}(0,\\sigma^2)$\n",
    "\n",
    "On en déduit que $n^\\alpha (\\frac{S_n}{n} - m)$ converge vers 0 (resp. $+\\infty$) en probabilité lorsque $\\alpha < 1/2$ (resp. $\\alpha > 1/2$)\n",
    "\n",
    "En particulier pour $\\alpha = 0$ : \n",
    "$$\\frac{S_n}{n} \\to^\\mathbb{P} m$$\n",
    "\n",
    "Soit $(\\Omega,\\mathcal{A},\\mathbb{P}_Z)$ l'espace probabilisé. Posons $Z_n$ le resultat du  n-ème tirage avec remise d'un élément de cet espace. Les $(Z_n)_\\mathbb{N}$ vérifient les ocnditions d'application du **théorême de la limite centrale**. \n",
    "\n",
    "\n",
    "\n",
    "D'où en considérant le vecteur aléatoire conditionnel $Y|X=x$. En notant Y les valeurs prises aux points de discretisation sans observation et X les valeurs prises par les composantes aux sites d'observation. On a alors sans perte de généralité $Z = (X,Y)$ par permutations.\n",
    "\n",
    "La moyenne des simulations conditionelles converge vers l'espérance conditionelle. **Il est donc approprié de l'approcher de cette façon.**\n",
    "\n",
    "> **2. Rappeler la loi conditionnelle du vecteur des composantes de Z correspondant aux points de discrétisation sans observation, connaissant les valeurs prises par les composantes aux sites d’observation.**\n",
    "\n",
    "Le vecteur aléatoire des composantes de $Z$ correspondant aux points de discrétisation sans observation, connaissant les valeurs prises par les composantes aux sites d’observation est noté $Z'$\n",
    "\n",
    "En notant $Y$ les valeurs prises aux points de discretisation sans observation et $X$ les valeurs prises par les composantes aux sites d'observation. On a alors sans perte de généralité $Z = (X,Y)$ par permutations.\n",
    "\n",
    "$Z'= Z|X=x = Y|X=x$ admet une densité $f_{Y|X=x}$\n",
    "telle que \n",
    "$$f_{Y|X=x} =\\frac{1}{(2\\pi)^{k/2}\\sqrt{det(CS_Y)}}exp(-\\frac{1}{2}(y-\\Psi(x))^\\perp CS_Y^{-1}(y-\\Psi (x)))$$\n",
    "\n",
    "avec : \n",
    "$$\n",
    "CS_Y = C_Y - C_{Y,X}C_X^{-1}C_{X,Y} \n",
    "$$\n",
    "\n",
    "où on a  :\n",
    "\n",
    "$$\n",
    "E(Y|X=x) = \\Psi(z)= m_Y + C_{Y,Z}C_Z^{-1}(z-m_Z)\n",
    "$$\n",
    "\n",
    "\n",
    "> **3. Si Y = (Y1, . . . , Yp) est un vecteur de composantes gaussiennes indépendantes, toutes d’espérance nulle et de variance 1, quelle est la loi du vecteur Z = m + RY où R est une matrice p × p et m est un vecteur de taille p ?**\n",
    "\n",
    "Si Y est un vecteur de composantes gaussiennes indépendantes, toutes d'esperance nulle et de variance 1,  alors on peut caractériser cette variable aléatoire par sa fonction caractéristiques $\\Phi_Y(u) =e^{i<u|m>-\\frac{1}{2} <u|I_n u>}$\n",
    "\n",
    "Or d'après le cours de Probabilté $III$ $\\Phi_Z(u) = \\Phi_{m+RY}(u) = e^{i<u|m>}\\Phi_Y(R^\\perp u)$\n",
    "\n",
    "Ce qui dans notre cas nous donne : \n",
    "\n",
    "$$\\Phi_Z(u) = \\Phi_{m+RY}(u) = e^{i<u|m>}\\Phi_Y(R^\\perp u)$$\n",
    "\n",
    "Donc Z suit la loi qui a pour fonction caractéristique : \n",
    "$$\n",
    "\\Phi_Z(u) = \\Phi_{m+RY}(u) = e^{i<u|m>-\\frac{1}{2} <R^\\perp u| R^\\perp u>}\n",
    "$$\n",
    "\n",
    "\n",
    "> **4. En déduire un algorithme de simulation conditionnelle.**\n",
    "\n",
    "On en déduit donc qu'en utilisant une matrice R bien choisie on peut arriver simuler un vecteur gaussien conditionnel\n",
    "\n",
    "En effet si on choisit la transformée de Cholesky de la matrice de covariance conditionelle $CS_Y$, que l'on notera $R$ :\n",
    "En posant $Z'  = m +RY$ où $Y = (Y1, . . . , Yp)$ est un vecteur de composantes gaussiennes indépendantes, toutes d’espérance nulle et de variance 1\n",
    "\n",
    "$\\Phi_{Z'}(u) = e^{i<u|m> -\\frac{1}{2}<R^\\perp u|R^\\perp u> }\n",
    " =  e^{i< u|m> -\\frac{1}{2} <u|CS_Yu>}$ ( par symétrie de R ) \n",
    " \n",
    "$$\n",
    "\\Phi_{Z'}(u) = e^{i<u| m>-\\frac{1}{2} <u|CS_Yu>}\n",
    "$$\n",
    "\n",
    "Donc $Z'$ est une variable aléatoire à densité, $Z'$ est un un vecteur gaussien\n",
    "\n",
    "De plus Z'est de même loi que la variable aléatoire gaussienne $Y|X=x$ par identification des fonctions caractéristiques.\n",
    "\n",
    "On peut donc proposer un algorithme de simulation : \n",
    "\n",
    "### Algorithme de simulation\n",
    "--------\n",
    "\n",
    "- Fixer les vealeurs aux points d'observations \n",
    "- Calculer la matrice de covariance conditionelle\n",
    "- Calculer la transformée de Cholesky\n",
    "- Simuler Y un vecteur gaussien centré réduit de composantes indépendantes\n",
    "- Simuler Z par transformation affine\n",
    "- Recommencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement dee dépendances \n",
    "\n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrétisation\n",
    "A=0\n",
    "B=500\n",
    "N=101\n",
    "\n",
    "#Nombre de points de discrétisation \n",
    "Delta = (B-A)/(N-1)\n",
    "print(Delta)\n",
    "discretization_indexes = np.arange(N) \n",
    "discretization = discretization_indexes*Delta \n",
    "\n",
    "#Paramètres du modèle\n",
    "mu=-5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "\n",
    "#Données\n",
    "observation_indexes = [0,20,40,60,80,100]\n",
    "depth = np.array([0,-4,-12.8,-1,-6.5,0])\n",
    "#Indices des composantes correspondant aux observations et aux componsantes non observées\n",
    "unknown_indexes=list(set(discretization_indexes)-set(observation_indexes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_vect = [mu for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C(h, a, sig_2):\n",
    "    return (np.exp(-abs(h)/a)*sig_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_distance(discretization):\n",
    "    M=np.ones((len(discretization),len(discretization)))\n",
    "    for i in range(len(discretization)):\n",
    "        for j in range(len(discretization)):\n",
    "            M[i,j] = abs(discretization[i] - discretization[j])\n",
    "    return M "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar = C(mat_distance(discretization), a, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = np.array(observation_indexes, dtype=np.intp)\n",
    "columns = np.array(observation_indexes, dtype=np.intp)\n",
    "covar_obs_obs = covar[rows[:, np.newaxis], columns]\n",
    "\n",
    "rows = np.array(unknown_indexes, dtype=np.intp)\n",
    "columns = np.array(unknown_indexes, dtype=np.intp)\n",
    "covar_unk_unk = covar[rows[:, np.newaxis], columns]\n",
    "\n",
    "columns = np.array(unknown_indexes, dtype=np.intp)\n",
    "rows = np.array(observation_indexes, dtype=np.intp)\n",
    "covar_obs_unk= covar[rows[:, np.newaxis], columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_cond = np.array([mu for i in range(len(unknown_indexes))]) +  covar_obs_unk.transpose() @ np.linalg.inv(covar_obs_obs)@(np.array(depth) - [mu for i in range( len( observation_indexes)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_cond = covar_unk_unk - covar_obs_unk.transpose()@np.linalg.inv(covar_obs_obs) @ covar_obs_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([ cov_cond[i,i] for i in range (len(cov_cond))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(unknown_indexes,esp_cond)\n",
    "plt.scatter(observation_indexes,depth)\n",
    "plt.plot(unknown_indexes,X)\n",
    "plt.plot(builder([0,0,0,0,0,0],observation_indexes,X,N))\n",
    "\n",
    "plt.plot(builder(depth,observation_indexes,esp_cond+X,N))\n",
    "plt.plot(builder(depth,observation_indexes,esp_cond-X,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.linalg.cholesky(cov_cond)\n",
    "L = L.transpose()\n",
    "\n",
    "def simul( L ):\n",
    "    f= lambda u,v : np.sqrt(-2*np.log(u))*np.cos(2*np.pi*v)\n",
    "    g= lambda u,v : np.sqrt(-2*np.log(u))*np.sin(2*np.pi*v)\n",
    "    Y = np.random.normal(0,1,len(unknown_indexes))\n",
    "    Z = np.array([mu for i in range(len( unknown_indexes))])+ L@ Y\n",
    "    return Z\n",
    "Z = simul(L)\n",
    "plt.plot(unknown_indexes,Z)\n",
    "\n",
    "\n",
    "plt.plot(unknown_indexes, esp_cond)\n",
    "plt.plot(builder(depth,observation_indexes,esp_cond+X,N))\n",
    "plt.plot(builder(depth,observation_indexes,esp_cond-X,N))\n",
    "plt.scatter(observation_indexes,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def builder(depth,observation_indexes, Z , N):\n",
    "    prof = []\n",
    "    depth_ =list(depth)\n",
    "    Z_ = list(Z)\n",
    "    for i in range (N):\n",
    "\n",
    "        if i in observation_indexes :\n",
    "            prof.append(depth_.pop(0))\n",
    "        else : \n",
    "            prof.append(Z_.pop(0))\n",
    "    return prof\n",
    "prof = builder(depth, observation_indexes,Z,N)\n",
    "\n",
    "plt.plot(unknown_indexes, esp_cond)\n",
    "plt.plot(prof)\n",
    "plt.scatter(observation_indexes,depth)\n",
    "plt.plot(builder(depth,observation_indexes,esp_cond,N))\n",
    "\n",
    "def longueur ( prof, delta):\n",
    "    S = 0\n",
    "    for i in range(1,len(prof)):\n",
    "        S+= np.sqrt(delta**2 +(prof[i]-prof[i-1])**2)\n",
    "    return S\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simul_N ( Number , Delta):\n",
    "    length = []\n",
    "    for i in range (Number):\n",
    "        length.append(longueur(builder(depth,observation_indexes,simul(L),N),Delta))\n",
    "    return length\n",
    "\n",
    "np.array(simul_N(100,Delta)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Delta)\n",
    "L_th = longueur(builder(depth,observation_indexes,esp_cond,N),Delta)\n",
    "L_th\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 // 1000 // 10000 // 100000 simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simul_total = simul_N(1000,Delta)\n",
    "\n",
    "info = []\n",
    "num = [100,1000,100,100]\n",
    "subplot_list = [221,222,223,224]\n",
    "\n",
    "for borne, sub in zip(num,subplot_list):\n",
    "    means = []\n",
    "    simuls = np.array(simul_total[:borne])\n",
    "    for i in range(1,len(simuls)):\n",
    "        plt.subplot(sub)\n",
    "        means.append(np.array(simuls[:i]).mean())\n",
    "        plt.plot(means)\n",
    "    info.append({ \n",
    "                ,mean : simuls.mean()\n",
    "                ,std : simuls.std()\n",
    "                ,conf : 1.960*std/np.sqrt(len(simuls))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(simuls, bins = np.arange(simuls.min(),simuls.max(),0.5), align = 'left')\n",
    "plt.axvline(x=mean, linewidth=1, color='r', label = \"moyenne des longueurs\")\n",
    "plt.axvline(x=mean +std, linewidth=1, color='g')\n",
    "plt.axvline(x=mean - std, linewidth=1, color='g')\n",
    "plt.axvline(x=mean - conf, linewidth=1, color='y')\n",
    "plt.axvline(x=mean + conf, linewidth=1, color='y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculer la fonction de répartition expérimentale\n",
    "\n",
    "def F_repart(level, simuls):\n",
    "    S = 0\n",
    "    for i in simuls:\n",
    "        if i >level :\n",
    "            S+=1\n",
    "    return  1 - S/len(simuls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1- F_repart(525,simuls)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Partie info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discrétisation\n",
    "A=0\n",
    "B=500\n",
    "N=101\n",
    "\n",
    "#Nombre de points de discrétisation \n",
    "Delta = (B-A)/(N-1)\n",
    "print(Delta)\n",
    "discretization_indexes = np.arange(N) \n",
    "discretization = discretization_indexes*Delta \n",
    "\n",
    "#Paramètres du modèle\n",
    "mu=-5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "\n",
    "#Données\n",
    "observation_indexes = [0,20,40,60,80,100]\n",
    "depth = np.array([0,-4,-12.8,-1,-6.5,0])\n",
    "#Indices des composantes correspondant aux observations et aux componsantes non observées\n",
    "unknown_indexes=list(set(discretization_indexes)-set(observation_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Covariance entre deux points \n",
    "def C(Mat_dist, a, sigma2):\n",
    "    Mat_C=np.ones((len(Mat_dist), len(Mat_dist)))\n",
    "    for i in range(len(Mat_dist)):\n",
    "        for j in range(len(Mat_dist)):\n",
    "            Mat_C[i][j]=sigma2*np.exp(abs(Mat_dist[i][j])/a)\n",
    "    return Mat_C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Construction matrice de distance\n",
    "def mat_distance(discretization):\n",
    "    M=np.ones((len(discretization),len(discretization)))\n",
    "    for i in range(len(discretization)):\n",
    "        for j in range(len(discretization)):\n",
    "            M[i,j] = abs(discretization[i] - discretization[j])\n",
    "    return M \n",
    "\n",
    "Mat_dist=distance(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Calcul de la matrice de covariance\n",
    "covar = C(mat_distance(discretization), a, sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Extraction des matrices de covariances\n",
    "\n",
    "## entre observations \n",
    "rows = np.array(observation_indexes, dtype=np.intp)\n",
    "columns = np.array(observation_indexes, dtype=np.intp)\n",
    "covar_obs_obs = covar[rows[:, np.newaxis], columns]\n",
    "## entre inconnues\n",
    "rows = np.array(unknown_indexes, dtype=np.intp)\n",
    "columns = np.array(unknown_indexes, dtype=np.intp)\n",
    "covar_unk_unk = covar[rows[:, np.newaxis], columns]\n",
    "## entre inconnues-observations\n",
    "columns = np.array(unknown_indexes, dtype=np.intp)\n",
    "rows = np.array(observation_indexes, dtype=np.intp)\n",
    "covar_obs_unk= covar[rows[:, np.newaxis], columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction Utile\n",
    "def builder(depth,observation_indexes, Z , N):\n",
    "    prof = []\n",
    "    depth_ =list(depth)\n",
    "    Z_ = list(Z)\n",
    "    for i in range (N):\n",
    "\n",
    "        if i in observation_indexes :\n",
    "            prof.append(depth_.pop(0))\n",
    "        else : \n",
    "            prof.append(Z_.pop(0))\n",
    "    return prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calcul de l'espérance conditionelle et représentation\n",
    "esp_cond = np.array([mu for i in range(len(unknown_indexes))]) +  covar_obs_unk.transpose() @ np.linalg.inv(covar_obs_obs)@(np.array(depth) - [mu for i in range( len( observation_indexes)) ])\n",
    "plt.scatter(unknown_indexes,esp_cond, label = \"Espérance Conditionelle\")\n",
    "plt.scatter(observation_indexes,depth, label = 'Valeur observée')\n",
    "plt.xlabel('Indice discrétisation')\n",
    "plt.ylabel(\"Altitude\")\n",
    "plt.title(\"Tracé de l'espérance conditionelle\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Calcul matrice de covariance conditionelle / Affichage variance Codnitionelle\n",
    "cov_cond = covar_unk_unk - covar_obs_unk.transpose()@np.linalg.inv(covar_obs_obs) @ covar_obs_unk\n",
    "var_cond=np.array([ cov_cond[i,i] for i in range (len(cov_cond))])\n",
    "plt.scatter(unknown_indexes,esp_cond)\n",
    "plt.scatter(observation_indexes,depth)\n",
    "plt.tick_params(axis='y', labelcolor='tab:red')\n",
    "plt.ylabel('Altitude')\n",
    "plt.xlabel('Indice de discrétisation')\n",
    "plt.twinx()\n",
    "plt.plot(builder([0,0,0,0,0,0],observation_indexes,var_cond,N),label = 'Variance Conditionelle')\n",
    "plt.ylabel(\"Variance\")\n",
    "plt.title('affichage de la variance conditionelle')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**On remarque que la variance conditionelle est très faible au voisinage des points d'observation. Mais au contraire atteint un maximum au milieu des deux observations. La dispersion des données est bien plus importante quand la distance à un point d'observation augmente ( dans le cas où tous les points inconnues sont indépendants).** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Simulation conditionelle\n",
    "L = np.linalg.cholesky(cov_cond)\n",
    "L = L.transpose()\n",
    "\n",
    "def simul( L ):\n",
    "    f= lambda u,v : np.sqrt(-2*np.log(u))*np.cos(2*np.pi*v)\n",
    "    g= lambda u,v : np.sqrt(-2*np.log(u))*np.sin(2*np.pi*v)\n",
    "    Y = np.random.normal(0,1,len(unknown_indexes))\n",
    "    Z = np.array([mu for i in range(len( unknown_indexes))])+ L@ Y\n",
    "    return Z\n",
    "\n",
    "Z = simul(L)\n",
    "\n",
    "plt.plot(builder(depth,observation_indexes,Z,N),label = \"Simulation\")\n",
    "plt.plot(builder(depth,observation_indexes,esp_cond,N), label = 'Espérance conditionelle')\n",
    "plt.scatter(observation_indexes,depth)\n",
    "plt.title('Une simulation')\n",
    "plt.xlabel(\"Indice de discrétisation\")\n",
    "plt.ylabel(\"Altitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Fonction de longueur\n",
    "\n",
    "def longueur ( prof, delta):\n",
    "    S = 0\n",
    "    for i in range(1,len(prof)):\n",
    "        S+= np.sqrt(delta**2 +(prof[i]-prof[i-1])**2)\n",
    "    return S\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondad32e58c4a40f44d89753938273e31b60"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}